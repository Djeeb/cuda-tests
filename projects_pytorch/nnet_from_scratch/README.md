# Implementing a neural net from scratch using libtorch data structure (on MNIST)
The aim of this section is to precisely describe how to implement a 1-layer simple neural network using SGD on both mathematical and coding side. It will be trained on MNIST database to illustrate the theory. 

**Table of contents**
- Mathematical side
    - Neural network steps
    - structure used
    - computing backward propagation
- Coding side

    - 
  
 
## Mathematical side

### Neural network steps

1- Parameters initialization

![equation](https://latex.codecogs.com/png.latex?%5Cdpi%7B200%7D%20%5Clarge%20W_%7B1%7D%20%5Csim%20%5Cmathcal%7BN%7D%280%2C1%29%20%5Cin%20%5Cmathbb%7BR%7D%5E%7B64%5Ctimes784%7D)

2- Forward propagation

3- Cost computing

4- Backward propagation

5- Parameters update

6- Model evaluation

## Structure used
blabla

## Computing backward propagation
