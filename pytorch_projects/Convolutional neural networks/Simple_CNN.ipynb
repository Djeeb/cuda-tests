{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Simple convolutional neural network with Pytorch</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers.*\n",
    "\n",
    "__Deep Learning__, I. Goodfellow & al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim in this section is to use multiple methods introduced by CNN in order to outperform simple fully connected neural networks. We will first describe each method and explain the motivation behind. Then, we will train a model using all these methods and compare it to simple neural networks. \n",
    "\n",
    "Note : we will mostly use __Deep Learning__, I. Goodfellow & al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **I- [ The convolution operator as an accelerator](#convolution)**\n",
    "\t- 1- [principle of convolution](#principle_conv)\n",
    "\t- 2- [motivation behind convolution](#motivation_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"convolution\"></a>\n",
    "# I- The convolution operator as an accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"principle_conv\"></a>\n",
    "## 1. Principle of convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution is a bilinear operation between two functions $ f $ and $ g $  that share the same domain $ \\mathcal{D} $ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ (f,g) \\mapsto f*g $$ \n",
    "\n",
    "## $$ \\forall x \\in \\mathcal{D}\\:\\: (f*g)(x)\\: = \\int f(t)g(x-t)dt $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathematics, this operation is generalizing the concept of *moving average*. Indeed, it can been seen as a weighted average of function $f$ where $g$ plays the role of the weight function. \n",
    "\n",
    "In the case of CNN, if we consider that our data is a bit noisy, the idea is to create a weighted average of an input in order to smooth the output and therefore reduce the impact of the noise. Of course, we have a limited amount of features and we work in a discrete space. For a two dimensional image $X$, and a two-dimensional weight $W$ of size $(m \\times n)$ the convolution operation consists in : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ (X*W)_{(i,j)} = \\sum_{m} \\sum_{n} X_{(m,n)}W_{(i-m,j-n)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $X$ is called the **input**\n",
    "- $W$ is called the **kernel**\n",
    "- the result is called the **feature map**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a 2-convolution. The output is calculated in positions where the kernel *fits* inside the input (it is called a *valid* convolution). In this case, the kernel has always only 4 non-zero parameters, which is why we can graphically and computationnaly represent it as a $4 \\times 4$ matrix :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.d2l.ai/_images/conv-pad.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"motivation_conv\"></a>\n",
    "## 2. Motivation behind convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution operation has dramatically changed the way we design neural networks for 3 main reasons : models are **faster**, require **less memory**, and are more able to **detect patterns** in images and time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Sparse interactions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of creating fully connected nodes, convolution sets up a new neural architecture based on sparse interactions : only a **limited amount of input nodes is linked with an output node**. In the case of an image processing, it is useful as it can be seen as a *feature detection* such as edges, etc. Above all, it drastically decreases the number of operations to compute and therefore the model training converges more easily. The **complexity** of the algorithm is clearly decreased. \n",
    "\n",
    "For example, let say our input size is $n$ and output size $m$. In a fully connected neural network, the parameter $W$ size would be $n \\times m$ while we can limit the number of interactions in a CNN and create a parameter $W'$ of size $k \\times m$ with $k << n$. In terms of complexity, we have : \n",
    "\n",
    "- $\\mathcal{O}(n \\times m)$ for fully connected NN\n",
    "- $\\mathcal{O}(k \\times m)$ for CNN\n",
    "\n",
    "Below is a drawing of sparse connected layers vs fully connected layers. As we can see, only a few inputs are used to compute $s_{3}$ : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/468/1*jkhJotQX3uz-Ja7QDOKQBg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Parameter sharing :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During a forward propagation of an input in a fully layer, an element of the weight matrix is used only once, while it is used multiple times in a CNN. In the example above (see *Principle of convolution*) each parameter is used 16 times (i.e. the dimension of the output). We call them **tied parameters**. It does not affect the computation time but it helps reducing the memory needed to store weights during the execution of the learning task. So, if we keep the same notations as before, we already said we only needed a $k \\times n$ weight matrix. Actually, we can go deeper as the parameters used are the same during the $m$ computations : \n",
    "\n",
    "- $W \\in \\mathbb{R}^{n \\times m}$ for fully connected NN\n",
    "- $W' \\in \\mathbb{R}^{k}$ for CNN\n",
    "\n",
    "Of course, $k << n \\times m$ in practice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Equivariance :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, the term of equivariance is used when the order of the application of two functions does not affect the result. Given an input $x$ : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ f \\circ  g (x) = g \\circ  f (x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of CNN, layers have a more specific property : **equivariance to translation**. It means that no matter if you shift an image or a time serie before or after the convolution process, the result will be the same. However it is not the case for rotation or scaling. It enables features and patterns detection : edges that looks the same in an image, trends that are similar in a time serie, will be roughly processed in the same way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"pooling\"></a>\n",
    "# II- Pooling to improve statistic robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"what_pooling\"></a>\n",
    "## 1. What is pooling ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling consists in **summing-up** information contained in the input by reducing its size. When it is well used, it creates **statistical robustness** and help to make **data smaller** before being processed again. Below is a max pooling over the 4 parts of an input : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.datascience.com/hs-fs/hubfs/CNN%204.png?width=600&name=CNN%204.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image processing, if the goal of the learning task is to detect whether there is a specific object or not (rather than its specific location on an image), pooling is very useful as it is **invariant to small translations**. Using pooling makes the assumption that the function we want to approximate is quite invariante to small shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"different_pooling\"></a>\n",
    "## 2. Different ways of pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - The choice of the operator :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAHiCAYAAAA037JSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucHGWd7/HvNwkRIYEkZsBACAFkWVh2BRxzuLgYRTAgEHgtq4ACAhrcldseQCMchVX2HBRlvYC6kbBcRASDkbsSucgiEJmEAMEQgUggEMhgIARQIfg7f3RFmmFqplP9dHVPz+f9evWru+upp+s3NdO/+s1TT1c7IgQAAIB0hjQ7AAAAgHZDgQUAAJAYBRYAAEBiFFgAAACJUWABAAAkRoEFAACQGAVWm7H9fdtfTL1uP68z0XbYHlbvawEAGs/2xbbPzh7/o+3FzY6p3XBAbDMR8ZlGrAsAaE8R8T+Stmt2HO2GEaw2Yntos2MAAAAUWAOC7e1t3277BdsP2T4wW36x7e/ZvtH2y5I+UD3sm63zOdvLbT9t+1PZqbx3VfVfO0Q82fYy26fYXpH1ObrqdT5i+z7bL9p+0vZZ5e4FAGgc24/bPs32A7Zftj3T9qa2b7K92vYvbY+uWn9X23dlefl+25Or2o62vSjrt8T2cVVtfebaXuK63fb/s/0b26tsX2N7TFX7gdlx4YVs3e2r2no9dvSyjcm2l/XYF6dm+2KV7Sttr1/VnntcwRsosFqc7fUkXSfpZkmbSDpB0uW21w7nHi7pPySNlHRnj75TJP1vSR+S9C5J7+9nc++UtLGkzSUdK+mCqoTysqQjJY2S9BFJ/2L7oLp+OABoLf8kaW9JfyPpAEk3STpd0lhVjpcnSpLtzSXdIOlsSWMknSrpatsd2euskLS/pI0kHS3pP23vUrWdvnJtb46UdIykzSStkfTtLI6/kXSFpJMldUi6UdJ1tofXcOzoz0clTZG0laR/kPTJbJvrelwZtCiwWt+ukkZIOiciXo2IWyVdL+mwrP2aiPh1RPwlIv7Uo+9HJf13RDwUEa9I+vd+tvWapC9HxGsRcaOkl5Sdl4+I2yPiwWw7D6jypuaNBaCdfCcino2IpyT9j6S5EXFfRPxZ0mxJO2frfULSjRFxY5YT50jqkrSfJEXEDRHxWFT8SpUi5x+rtpOba3NcFhELI+JlSV+U9NFsSsjHJN0QEXMi4jVJX5f0dkm7q/9jR3++HRFPR8RKVQq1nbLl63pcGbQosFrfZpKejIi/VC1bqsp/PpL0ZH99q573ta4k/SEi1lQ9f0WVN6hs/y/bt9nutr1K0mdU+a8OANrFs1WP/9jL8xHZ4y0l/XN26u0F2y9Iep+kcZJke1/b99hembXtpzfny9xcm6M6dy+VtF72eptlzyVJ2XHiSVWOD/0dO/rzTE5863pcGbQosFrf05K2sF39u5og6anscfTRd7mk8VXPt6gjjh9JulbSFhGxsaTvS3IdrwcAA9WTqowqjaq6bRgR59h+m6SrVRlN2jQiRqly6q6efFmduyeoMgL2nCrHhy3XNth2tu5T6v/YUVTK40pbo8BqfXNVmf/0OdvrZRMpD5D04xr6XiXp6Gyi4waSvlRHHCMlrYyIP9mepMrcLwAYjH4o6QDbH7Y91Pb62UTx8ZKGS3qbpG5Ja2zvK2mfOrf3Cds7ZHn8y5JmRcTrquT4j9jeK5tzdYqkP0u6S/UdO/qS8rjS1iiwWlxEvCrpQEn7qvIfy3clHRkRD9fQ9yZVJkPeJulRSXdnTX8uEMq/Svqy7dWqvKGuKvAaADDgRcSTkqaqMgG+W5URrdMkDYmI1apMhr9K0vOq/DN6bZ2bvEzSxaqctls/e31FxGJV5oN9R5XjwwGSDsjmXBU+dvQl8XGlrTmirzNMaCfZx3cXSnpbj/P/AIAWZPt2ST+MiAubHUtvOK7kYwSrzdk+OPvI7mhJX5V0HW8CAEBRHFdqQ4HV/o5TZQj7MUmvS/qX5oYDABjgOK7UgFOEAAAAiTGCBQAAkBgFFgAAQGLD6umcfSfRtyQNlXRhRJzT1/pjx46NiRMn1rNJoO3MmzfvuYjo6H9NoFzkbOCtas3ZhQus7HuQLlDlizGXSbrX9rUR8du8PhMnTlRXV1fRTQJtyfbS/tcCykfOBt6q1pxdzynCSZIejYgl2QXNfqzKhdcAAAAGtXoKrM315i95XKZevkTS9jTbXba7uru769gcAKBetqfYXmz7UdvTmx0P0K7qKbB6++LKt1zzISJmRERnRHR2dDDNBACapWpqx76SdpB0mO0dmhsV0J7qKbCW6c3foj1elW/vBgC0JqZ2ACWpp8C6V9K2treyPVzSoar/Cy0BAI1T09QOAPUr/CnCiFhj+3hJv1DlMg0XRcRDySIDAKTW79QO29MkTZOkCRMmlBET0Jbqug5WRNwo6cZEsQAAGqvfqR0RMUPSDEnq7Ozku9SAgriSOwAMHkztAEpS1wgWAGDgYGoHUB4KLAAYRJjaAZSDU4QAAACJUWABAAAkRoEFAACQGAUWAABAYhRYAAAAiVFgAQAAJEaBBQAAkBgFFgAAQGIUWAAAAIlRYAEAACRGgQUAAJAYBRYAAEBiFFgAAACJUWABAAAkRoEFAACQGAUWAABAYsOaHQAAAIPFa6+9VqjfmjVrCvW7++67C/UbNWpUoX733HNPoX6SNGLEiEL9jjzyyMLbbCRGsAAAABKjwAIAAEiMAgsABgnbW9i+zfYi2w/ZPqnZMQHtijlYADB4rJF0SkTMtz1S0jzbcyLit80ODGg3jGABwCAREcsjYn72eLWkRZI2b25UQHuiwAKAQcj2REk7S5rb3EiA9lTXKULbj0taLel1SWsiojNFUKjd66+/ntu2atWq5Ns7//zzc9teeeWV3LbFixfntl1wwQW5baeeempu2xVXXJHbJknrr79+btv06dNz284888w+XxcY6GyPkHS1pJMj4sUebdMkTZOkCRMmNCE6oD2kGMH6QETsRHEFAK3P9nqqFFeXR8RPe7ZHxIyI6IyIzo6OjvIDBNoEpwgBYJCwbUkzJS2KiPOaHQ/QzuotsELSzbbnZcPKAIDWtYekIyR90PaC7LZfs4MC2lG9l2nYIyKetr2JpDm2H46IO6pX4Hw+ALSGiLhTkpsdBzAY1DWCFRFPZ/crJM2WNKmXdTifDwAABpXCBZbtDbML1cn2hpL2kbQwVWAAAAADVT2nCDeVNLsyZ1LDJP0oIn6eJKoB7Iknnshte/XVV3Pb7rrrrty2O++8M7fthRdeyG27+uqrc9vKNn78+Ny2E088Mbdt9uzZuW0jR47sc5vvfve7c9ve//7399kXwMDx0ksvFe571llnFeo3f/78Qv0efPDBQv2ee+65Qv2KOumkYt+i1NcxqT+HHHJI4b6tqHCBFRFLJOUfwQAAAAYpLtMAAACQGAUWAABAYhRYAAAAiVFgAQAAJEaBBQAAkFi9V3IfdO67774+2/faa6/ctlWrVqUOp6UMGZJfr5999tm5bRtuuGFu2+GHH57bttlmm/UZz+jRo3Pbtttuuz77AgBQD0awAAAAEqPAAgAASIwCCwAAIDEKLAAAgMQosAAAABKjwAIAAEiMAgsAACAxroO1jrbccss+29/xjnfktrXSdbAmTZqU29bX9aNuu+223Lbhw4fnth1xxBG1BQYA62j99dcv3Hfx4sWF+j355JOF+v3pT38q1G/mzJmF+l1//fWF+n3zm98s1A9vYAQLAAAgMQosAACAxCiwAGAQsT3U9n22i507AlATCiwAGFxOkrSo2UEA7Y4CCwAGCdvjJX1E0oXNjgVodxRYADB4fFPS5yT9JW8F29Nsd9nu6u7uLi8yoM1wmYZ1NGbMmD7bzz333Ny2vj4uu9NOO+W2nXTSSf0Hto6vOWfOnNy2ESNG5LYtXLgwt+3b3/52bYEBKJ3t/SWtiIh5tifnrRcRMyTNkKTOzs4oKTyg7TCCBQCDwx6SDrT9uKQfS/qg7R82NySgfVFgAcAgEBFfiIjxETFR0qGSbo2ITzQ5LKBtUWABAAAkxhwsABhkIuJ2Sbc3OQygrTGCBQAAkFi/BZbti2yvsL2watkY23NsP5Ld5387MAAAwCDjiL4/hWt7T0kvSbo0InbMln1N0sqIOMf2dEmjI+Lz/W2ss7Mzurq6EoQ9ML344ou5bSNHjsxtO+6443Lb+vqG9csuuyy37fDDD89tQ7lsz4uIzmbHAfQ0GHL266+/XqjfL37xi0L9vvKVrxTqd/fddxfqh/Rqzdn9jmBFxB2SVvZYPFXSJdnjSyQdtM4RAgAAtKmic7A2jYjlkpTdb5IuJAAAgIGt4ZPc+doFAAAw2BQtsJ61PU6SsvsVeStGxIyI6IyIzo6OjoKbAwAAGDiKFljXSjoqe3yUpGvShAMAADDw1XKZhisk3S1pO9vLbB8r6RxJe9t+RNLe2XMAAACohiu5R8RhOU17JY6l7W200UaF+m288caF+l144YW5bYceemhu25AhXH8WAIB6cCQFAABIjAILAAAgMQosAACAxCiwAAAAEqPAAgAASIwCCwAAILF+L9OA5jvzzDNz2+bNm5fb9qtf/Sq37Ze//GVu2z777FNbYAAwwA0dOrRQvylTphTqd/755xfq941vfKNQv4997GOF+o0fP75QP7yBESwAAIDEKLAAAAASo8ACgEHE9ijbs2w/bHuR7d2aHRPQjpiDBQCDy7ck/TwiDrE9XNIGzQ4IaEcUWAAwSNjeSNKekj4pSRHxqqRXmxkT0K44RQgAg8fWkrol/bft+2xfaHvDZgcFtCNGsAaAESNG5Lb94Ac/yG3bZZddcts+/elP57Z94AMfyG3r7OzMbfvsZz+b22Y7tw1AaYZJ2kXSCREx1/a3JE2X9MW1K9ieJmmaJE2YMKEpQQLtgBEsABg8lklaFhFzs+ezVCm4/ioiZkREZ0R0dnR0lB4g0C4osABgkIiIZyQ9aXu7bNFekn7bxJCAtsUpQgAYXE6QdHn2CcIlko5ucjxAW6LAAoBBJCIWSMqfTAkgCU4RAgAAJEaBBQAAkBinCAe4bbbZJrft4osvzm07+uj8aReXXXZZobaXX345t+3II4/MbRs3blxuGwC0oiFDio1PXHrppYX6HXHEEYX6nX/++YX6zZo1q1C/97znPYX6tSNGsAAAABKjwAIAAEiMAgsAACAxCiwAAIDEKLAAAAASo8ACAABIrN/LNNi+SNL+klZExI7ZsrMkfVpSd7ba6RFxY6OCRDEHH3xwbtu73vWu3LZTTjklt+2WW27JbTv99NNz25YuXVqo3/jx43PbAABoVbWMYF0saUovy/8zInbKbhRXAAAAmX4LrIi4Q9LKEmIBAABoC/XMwTre9gO2L7I9Om8l29Nsd9nu6u7uzlsNAACgbRQtsL4naRtJO0laLukbeStGxIyI6IyIzo6OjoKbAwAAGDgKFVgR8WxEvB4Rf5H0A0mT0oYFAAAwcBUqsGxXfzvvwZIWpgkHAABg4KvlMg1XSJosaaztZZLOlDTZ9k6SQtLjko5rYIxogL//+7/Pbbvqqqty26677rrctqOPPjq37b/+679y2x555JHctjlz5uS2AcBAM3bs2EL9+sq9fTnxxBML9dt7770L9VuyZEmhfpI0atSown1bUb8FVkQc1svimQ2IBQAAoC1wJXcAAIDEKLAAYBCx/W+2H7K90PYVttdvdkxAO6LAAoBBwvbmkk6U1Jl99dlQSYc2NyqgPVFgAcDgMkzS220Pk7SBpKebHA/QliiwAGCQiIinJH1d0hOqXCR6VUTc3NyogPbU76cIMfj09VHZI444IrftU5/6VG7bmjVrctvuuOOO3Lbbb789t23y5Mm5bQDeKvtas6mStpL0gqSf2P5ERPywap1pkqZJ0oQJE5oSJ9AOGMECgMHjQ5J+HxHdEfGapJ9K2r16Bb7eDEiDAgsABo8nJO1qewPblrSXpEVNjgloSxRYADBIRMRcSbMkzZf0oCrHgBlNDQpoU8zBAoBBJCLOVOUrzwA0ECNYAAAAiVFgAQAAJMYpwkHqgQceyG2bNWtWbtu9996b29bXpRj6ssMOO+S27bnnnoVeEwBa0f3331+o31e/+tVC/X7+858X6jdy5MhC/fq6zM9gwwgWAABAYhRYAAAAiVFgAQAAJEaBBQAAkBgFFgAAQGIUWAAAAIlxmYYBbvHixblt3/nOd3LbZs+endv2zDPP1BVTb4YOHZrbNm7cuNy2IUP4HwAAMPBw9AIAAEiMAgsAACAxCiwAAIDEKLAAAAASo8ACAABIjAILAAAgsX4v02B7C0mXSnqnpL9ImhER37I9RtKVkiZKelzSRyPi+caF2t76ujTCj370o9y2Cy64ILft8ccfryekddbZ2ZnbdsYZZ+S2HXjggY0IBwD6tWLFikL9vvSlLxXqd8kllxTqt9566xXq99nPfrZQv1NPPbVQP7yhlhGsNZJOiYjtJe0q6bO2d5A0XdItEbGtpFuy5wAAAINevwVWRCyPiPnZ49WSFknaXNJUSWtL8UskHdSoIAEAAAaSdZqDZXuipJ0lzZW0aUQslypFmKRNUgcHAFh3ti+yvcL2wqplY2zPsf1Idj+6mTEC7a7mAsv2CElXSzo5Il5ch37TbHfZ7uru7i4SIwBg3VwsaUqPZUzrAEpUU4Flez1ViqvLI+Kn2eJnbY/L2sdJ6nWmYETMiIjOiOjs6OhIETMAoA8RcYeklT0WM60DKFG/BZZtS5opaVFEnFfVdK2ko7LHR0m6Jn14AIBEmNYBlKjfyzRI2kPSEZIetL0gW3a6pHMkXWX7WElPSPrnxoQ4sDz77LO5bQ899FBu2wknnJDb9vDDD9cV07qaNGlSbtvnPve53LapU6fmtg0ZwiXXgIHA9jRJ0yRpwoQJTY4GGLj6LbAi4k5JzmneK204AIAGedb2uIhY3t+0DkkzJKmzszPKDBBoJwwrAMDgwLQOoEQUWADQZmxfIeluSdvZXpZN5ThH0t62H5G0d/YcQIPUMgcLADCARMRhOU1M6wBKwggWAABAYhRYAAAAiVFgAQAAJMYcrF6sXNnzAshvOO644/rsu2DBgty2JUuWFI6piN133z237ZRTTslt+/CHP5zb9va3v72umAAgz913312o37e+9a3C27zmmmIfpnz11VcL9evvGJLnrLPOKtRvk024nmyzMIIFAACQGAUWAABAYhRYAAAAiVFgAQAAJEaBBQAAkBgFFgAAQGJtfZmGuXPn5rade+65uW2/+c1vctueeuqpumIqoq9LI5x44om5baeffnpu24gRI+qKCQAA5GMECwAAIDEKLAAAgMQosAAAABKjwAIAAEiMAgsAACAxCiwAAIDE2voyDbNnzy7UVo/tt98+t+2AAw7IbRs6dGhu26mnnprbNmrUqNoCA4AWt2jRokL9/vZv/7bwNg8++OBC/XbZZZdC/bbddttC/TDwMIIFAACQGAUWAABAYhRYANBmbF9ke4XthVXLzrX9sO0HbM+2zfwCoIEosACg/VwsaUqPZXMk7RgR/yDpd5K+UHZQwGBCgQUAbSYi7pC0sseymyNiTfb0HknjSw8MGET6LbBsb2H7NtuLbD9k+6Rs+Vm2n7K9ILvt1/hwAQAJHCPppt4abE+z3WW7q7u7u+SwgPZRy2Ua1kg6JSLm2x4paZ7tOVnbf0bE1xsXXn3OOeecQm0A0K5sn6FKXr+8t/aImCFphiR1dnZGiaEBbaXfAisilktanj1ebXuRpM0bHRgAIC3bR0naX9JeEUHxBDTQOs3Bsj1R0s6S5maLjs8+kXKR7dGJYwMAJGJ7iqTPSzowIl5pdjxAu6u5wLI9QtLVkk6OiBclfU/SNpJ2UmWE6xs5/TifDwAlsn2FpLslbWd7me1jJZ0vaaSkOdm82e83NUigzdX0VTm211OluLo8In4qSRHxbFX7DyRd31tfzucDQLki4rBeFs8sPRBgEKvlU4RW5Y25KCLOq1o+rmq1gyUt7NkXAABgMKplBGsPSUdIetD2gmzZ6ZIOs72TpJD0uKTjGhIhAADAAFPLpwjvlORemm5MHw4AYLA65phjmh0CkAxXcgcAAEiMAgsAACAxCiwAAIDEKLAAAAASo8ACAABIjAILAAAgMQosAACAxCiwAAAAEqPAAgAASIwCCwAAIDEKLAAAgMQosAAAABKjwAIAAEjMEVHexuxuSUuzp2MlPVfaxvvXSvEQS75WiidVLFtGREeC1wGS6pGze2ql96LUWvEQS+9aKRapeDw15exSC6w3bdjuiojOpmy8F60UD7Hka6V4WikWoGyt9vffSvEQS+9aKRap8fFwihAAACAxCiwAAIDEmllgzWjitnvTSvEQS75WiqeVYgHK1mp//60UD7H0rpVikRocT9PmYAEAALQrThECAAAk1pQCy/YU24ttP2p7ejNiqIrlcdsP2l5gu6sJ27/I9grbC6uWjbE9x/Yj2f3oJsZylu2nsv2zwPZ+JcWyhe3bbC+y/ZDtk7Llpe+bPmJpyr4BytRfvrb9NttXZu1zbU9sUBy9vg97rDPZ9qqq9+SXGhFL1fb6PH644tvZvnnA9i4NimO7qp95ge0XbZ/cY52G7pt6jmW2j8rWecT2UQ2K5VzbD2e/h9m2R+X0TVcTRESpN0lDJT0maWtJwyXdL2mHsuOoiudxSWObuP09Je0iaWHVsq9Jmp49ni7pq02M5SxJpzZhv4yTtEv2eKSk30naoRn7po9YmrJvuHEr61ZLvpb0r5K+nz0+VNKVDYql1/dhj3UmS7q+xP3T5/FD0n6SbpJkSbtKmlvS7+wZVa7VVNq+KXoskzRG0pLsfnT2eHQDYtlH0rDs8Vfzjh0pa4JmjGBNkvRoRCyJiFcl/VjS1CbE0RIi4g5JK3ssnirpkuzxJZIOamIsTRERyyNifvZ4taRFkjZXE/ZNH7EA7a6WfF39npwlaS/bTh3IAH0fTpV0aVTcI2mU7XEN3uZekh6LiLwLxDZEHceyD0uaExErI+J5SXMkTUkdS0TcHBFrsqf3SBpfzzZq0YwCa3NJT1Y9X6bmvklC0s2259me1sQ4qm0aEculSlKRtEmT4zk+G1a9qKzTldWyUw47S5qrJu+bHrFITd43QIPVkq//uk52AFsl6R2NDKqX92G13Wzfb/sm23/XyDjU//GjGce7QyVdkdNW5r6RasvXzdhHx6gystibZDVBMwqs3v6zaeZHGfeIiF0k7Svps7b3bGIsreh7kraRtJOk5ZK+UebGbY+QdLWkkyPixTK3XUMsTd03QAlqydel5vR+csJ8VU6NvVvSdyT9rFFxZPo7fpS9b4ZLOlDST3ppLnvf1KrsfXSGpDWSLs9ZJVlN0IwCa5mkLaqej5f0dBPikCRFxNPZ/QpJs1UZEm+2Z9cOI2f3K5oVSEQ8GxGvR8RfJP1AJe4f2+upkkgvj4ifZoubsm96i6WZ+wYoSS35+q/r2B4maWM1aKpBTk74q4h4MSJeyh7fKGk922MbEUu2jf6OH2Uf7/aVND8inu3ZUPa+ydSSr0vbR9kE+v0lfTyyCVc9pawJmlFg3StpW9tbZdX2oZKubUIcsr2h7ZFrH6syCW5h371Kca2ktZ+kOErSNc0KpMd8gYNV0v7J5nDMlLQoIs6raip93+TF0qx9A5Solnxd/Z48RNKteQevevSRE6rXeefa+V+2J6lyjPtD6liy16/l+HGtpCOzTxPuKmnV2lNmDXKYck4PlrlvqtSSr38haR/bo7NpFvtky5KyPUXS5yUdGBGv5KyTtiZIMVN+XW+qfLLid6p8OuWMZsSQxbG1Kp+KuV/SQ82IRZU3w3JJr6lSyR+ryvyFWyQ9kt2PaWIsl0l6UNIDqrxZxpUUy/tUGSZ+QNKC7LZfM/ZNH7E0Zd9w41bmrbd8LenLqhyoJGl9VU5JPSrpN5K2blAcee/Dz0j6TLbO8Vkuv1+Vicy7N3C/9Hr86BGPJV2Q7bsHJXU2MJ4NVCmYNq5aVtq+WZdjmaROSRdW9T0m+/t5VNLRDYrlUVXmeq3921n7ydfNJN3Y1++06I0ruQMAACTGldwBAAASo8ACAABIjAILAAAgMQosAACAxCiwAAAAEqPAAgAASIwCCwAAIDEKLBRi+yzbP8weT7D9ku2hzY4LAJqlFXOh7Ym2I/saI2Vf9HxUf/1Qv2HNDgADX0Q8IWlEs+MAgGYaCLkwIvZtdgyDBSNYAAAAiVFglcT247ZPs/2A7Zdtz7S9aTZcu9r2L7Mvuly7/k9sP2N7le07bP9dtny47QW2T8ieD7X9a9tfytnuxba/b3tOtp1f2d6yqn132/dm27nX9u5VbZvZvtb2StuP2v50zjZ6DkHfbvsrWVyrbd9c/a3tto+0vdT2H2x/Mds3H6p3HwNAauuSu9c1F/bYzmTby2yfbvu5bLsfr2rf2Paltruz/Pl/bA/J2oZkz5faXpGtt3HOdm63/ans8Sdt32n767aft/172/tWrbtVdvxZ+3NesHZqCPpHgVWuf5K0t6S/kXSApJsknS5prCq/ixOr1r1J0raSNpE0X9LlkhQRr0r6hKQv295e0nRJQyX9Rx/b/bikr2TbWbD2tWyPkXSDpG+r8qWc50m6wfY7sn5XqPJFmZtJOkTS/7W9V40/6+GSjs7iHy7p1GybO0j6bhbTOEkbS9q8xtcEgGZYl9zdU6+5MMc7s9fcXNJRkmbY3i5r+44q+XJrSe+XdGT2upL0yez2gax9hKTza/zZ/pekxdl2vyZppm1nbT9S5Qu83yHpLElH1PiaEAVW2b4TEc9GxFOS/kfS3Ii4LyL+LGm2pJ3XrhgRF0XE6qztLEnvXvsfSUQslHR21udUSUdExOt9bPeGiLgje60zJO1mewtJH5H0SERcFhFrIuIKSQ9LOiBrf5+kz0fEnyJigaQLVfsb7L8j4ncR8UdJV0naKVt+iKTrIuLOrFj8kiS+cRxAK6s5d/ciLxfm+WJE/DkifqXKP8AfzSbNf0zSF7LjwuOSvqE38vHHJZ0XEUsi4iVJX5B06NqRtH4sjYgfZMeQS1T5x3dT2xMkvVd+3EnEAAAUiklEQVTSlyLi1Yi4U9K1NbweMhRY5Xq26vEfe3k+Qvrrab9zbD9m+0VJj2frVA8tXyJpoqQbI+KRfrb75NoH2ZtvpSqjUptJWtpj3aWq/Pe0maSVEbG6l7ZaPFP1+BW9MfFzsx7xvCLpDzW+JgA0Q025O0deLuzN8xHxctXzparkzLGqjH4t7dG2Nh/3zOVLVfkQ26Z9bOst8WX5WFmMa48Br1St+6RQMwqs1nS4pKmSPqTKkPDEbLmr1vmupOslfdj2+/p5vS3WPrA9QtIYSU9nty17rDtB0lNZ2xjbI3tpq8dySeOr4nm7KsPPADDYjba9YdXzCark4uckvaY35+vqfNwzl0+QtEZvLgTX1XJVjgEbVC3bIm9lvBUFVmsaKenPqozsbCDp/1Y32j5C0ntUOed+oqRLssIpz36232d7uCpzseZGxJOSbpT0N7YPtz3M9sck7SDp+qz9Lkn/z/b6tv9B0rHK5m/VYZYqpyB3z+L5d725cASAwezfXfkw0z9K2l/ST7LTd1dJ+g/bI7MPKv1vSWsnnF8h6d+ySekjVDlmXBkRa4oGERFLJXVJOiuLZzdV5p+hRhRYrelSVYZ4n5L0W0n3rG3Izot/U9KREfFSRPxIlTfBf/bxej+SdKYqpwbfo8r5ekXEH1R5A5+iSjH3OUn7R8RzWb/DVBk9e1qVeQZnRsScen6wiHhI0gmSfqzKf0irJa1QpaAEgMHsGUnPq5JzL5f0mYh4OGs7QdLLkpZIulOVvH5R1naRpMsk3SHp95L+lK1fr49L2k2V48PZkq4UubpmjmB+cTuzfbGkZRHxf5odS2+y/7ZekLRtRPy+2fEAQDPYnizphxExvr91m8X2lZIejogzmx3LQMAIFkpn+wDbG2RzDb4u6UG9MZEfANACbL/X9jbZdbamqDI3+GfNjmugoMBCM0zVG5Pst5V0aDCUCgCt5p2Sbpf0kirXS/yXiLivqRENIJwiBAAASIwRLAAAgMQosAAAABKr5TL6yYwdOzYmTpxY5iaBljdv3rznIqKj2XEAPZGzgbeqNWeXWmBNnDhRXV1dZW4SaHm2e35dEdASyNnAW9WaszlFCAAAkFhdBZbtKbYX237U9vRUQQEAGoO8DZSjcIFle6ikCyTtq8r31x1me4dUgQEA0iJvA+WpZwRrkqRHI2JJRLyqynfLTU0TFgCgAcjbQEnqKbA2l/Rk1fNl2TIAQGsibwMlqafAci/L3nJZeNvTbHfZ7uru7q5jcwCAOvWbt8nZQBr1FFjLJG1R9Xy8Kt8t9yYRMSMiOiOis6ODS/0AQBP1m7fJ2UAa9RRY90ra1vZWtodLOlTStWnCAgA0AHkbKEnhC41GxBrbx0v6haShki6KiIeSRQYASIq8DZSnriu5R8SNkm5MFAsAoMHI20A5uJI7AABAYhRYAAAAiVFgAQAAJEaBBQAAkBgFFgAAQGIUWAAAAIlRYAEAACRGgQUAAJAYBRYAAEBiFFgAAACJUWABAAAkRoEFAACQGAUWAABAYhRYAAAAiVFgAQAAJEaBBQAAkNiwZgeA+qxcubLU7X3ta18r1G/x4sWF+v3sZz8r1E+S1l9//UL9/vjHPxbeJgAAEiNYAAAAyVFgAQAAJEaBBQAAkFjhAsv2FrZvs73I9kO2T0oZGAAgLfI2UJ56JrmvkXRKRMy3PVLSPNtzIuK3iWIDAKRF3gZKUngEKyKWR8T87PFqSYskbZ4qMABAWuRtoDxJ5mDZnihpZ0lze2mbZrvLdld3d3eKzQEA6pSXt8nZQBp1F1i2R0i6WtLJEfFiz/aImBERnRHR2dHRUe/mAAB16itvk7OBNOoqsGyvp8qb9PKI+GmakAAAjULeBspRz6cILWmmpEURcV66kAAAjUDeBspTzwjWHpKOkPRB2wuy236J4gIApEfeBkpS+DINEXGnJCeMBQDQQORtoDxcyR0AACCxei402rbuu+++wn07OzsTRtI+xo8fX6jfkCHF/wfgdwGgP0888UShfrfddluhftddd12hfldffXWhfkVz6E9+8pNC/TbbbLNC/SRp1113Ldy3FTGCBQAAkBgFFgAAQGIUWAAAAIlRYAEAACRGgQUAAJAYBRYAAEBiFFgAAACJUWABAAAkRoEFAACQGAUWAABAYhRYAAAAiVFgAQAAJEaBBQAAkBgFFgAAQGLDmh1AK9pyyy2bHULDTZo0qVC/BQsWFOq3dOnSQv0AoJHmz59fqN/q1asL9XvssccK9YuIQv0WLlxYqN+OO+5YqB/ewAgWAABAYhRYAAAAidVdYNkeavs+29enCAgA0DjkbKAcKUawTpK0KMHrAAAaj5wNlKCuAsv2eEkfkXRhmnAAAI1CzgbKU+8I1jclfU7SXxLEAgBoLHI2UJLCBZbt/SWtiIh5/aw3zXaX7a7u7u6imwMA1IGcDZSrnhGsPSQdaPtxST+W9EHbP+y5UkTMiIjOiOjs6OioY3MAgDqQs4ESFS6wIuILETE+IiZKOlTSrRHxiWSRAQCSIWcD5eI6WAAAAIkl+aqciLhd0u0pXgsA0FjkbKDxGMECAABIjAILAAAgsSSnCNvNmDFjCvd9/vnnC/U79dRTC/WbOXNmoX6//vWvC/UbMoSaHED7OOigg0rd3qhRo0rd3o477ljq9vAGjpYAAACJUWABAAAkRoEFAACQGAUWAABAYhRYAAAAiVFgAQAAJEaBBQAAkBgFFgAAQGIUWAAAAIlRYAEAACRGgQUAAJAYBRYAAEBiFFgAAACJDWt2AO1mo402KtTvvPPOK9Rv5syZhfpttdVWhfqddtpphfodf/zxhfoBQDvZbbfdmh0CSsIIFgAAQGIUWAAAAInVVWDZHmV7lu2HbS+yzdgnALQw8jZQjnrnYH1L0s8j4hDbwyVtkCAmAEDjkLeBEhQusGxvJGlPSZ+UpIh4VdKracICAKRG3gbKU88pwq0ldUv6b9v32b7Q9oaJ4gIApEfeBkpST4E1TNIukr4XETtLelnS9J4r2Z5mu8t2V3d3dx2bAwDUqd+8Tc4G0qinwFomaVlEzM2ez1LljfsmETEjIjojorOjo6OOzQEA6tRv3iZnA2kULrAi4hlJT9reLlu0l6TfJokKAJAceRsoT72fIjxB0uXZJ1GWSDq6/pAAAA1E3gZKUFeBFRELJHUmigUA0GDkbaAcXMkdAAAgMQosAACAxOqdg4VERowYUajfrFmzCvU75JBDCvU76aSTCvX77W+LzaP97ne/W6gfALSibbbZplC/Bx98sFC/G264oVC/6dPfctUlrCNGsAAAABKjwAIAAEiMAgsAACAxCiwAAIDEKLAAAAASo8ACAABIjAILAAAgMQosAACAxCiwAAAAEqPAAgAASIwCCwAAIDEKLAAAgMQosAAAABJzRJS2sc7Ozujq6ipte8j3wgsvFOo3duzYQv2K/p3dcssthfpJ0uTJkwv3LZPteRHR2ew4gJ7I2YPXBz/4wUL9br311sSRtJ5aczYjWAAAAIlRYAEAACRWV4Fl+99sP2R7oe0rbK+fKjAAQHrkbaAchQss25tLOlFSZ0TsKGmopENTBQYASIu8DZSn3lOEwyS93fYwSRtIerr+kAAADUTeBkpQuMCKiKckfV3SE5KWS1oVETenCgwAkBZ5GyhPPacIR0uaKmkrSZtJ2tD2J3pZb5rtLttd3d3dxSMFANSllrxNzgbSqOcU4Yck/T4iuiPiNUk/lbR7z5UiYkZEdEZEZ0dHRx2bAwDUqd+8Tc4G0qinwHpC0q62N7BtSXtJWpQmLABAA5C3gZLUMwdrrqRZkuZLejB7rRmJ4gIAJEbeBsozrJ7OEXGmpDMTxQIAaDDyNlAOruQOAACQGAUWAABAYnWdIkTzHX/88YX6fe9730scSWPsueeezQ4BAJrugQceKNTvtNNOK9Rv+PDhhfrhDYxgAQAAJEaBBQAAkBgFFgAAQGIUWAAAAIlRYAEAACRGgQUAAJAYBRYAAEBiFFgAAACJUWABAAAkRoEFAACQGAUWAABAYhRYAAAAiVFgAQAAJDas2QG0m1tvvbVQv7333jtxJK1l9uzZhfoNGcL/AABazzPPPFOo32677Vao36abblqo31133VWoH7m3fuxBAACAxCiwAAAAEqPAAgAASKzfAsv2RbZX2F5YtWyM7Tm2H8nuRzc2TABArcjbQPPVMoJ1saQpPZZNl3RLRGwr6ZbsOQCgNVws8jbQVP0WWBFxh6SVPRZPlXRJ9vgSSQcljgsAUBB5G2i+onOwNo2I5ZKU3W+St6Ltaba7bHd1d3cX3BwAoE415W1yNpBGwye5R8SMiOiMiM6Ojo5Gbw4AUAdyNpBG0QLrWdvjJCm7X5EuJABAA5C3gRIVLbCulXRU9vgoSdekCQcA0CDkbaBEtVym4QpJd0vazvYy28dKOkfS3rYfkbR39hwA0ALI20Dz9ftdhBFxWE7TXoljAQAkQN4Gmo8ruQMAACRGgQUAAJBYv6cIB7JDDjmkUL/Zs2cnjqT1XH311YX6HXQQ1yYE0FpWrux5TdXavfe97y3Ub/ny5YX6rVhR7MObI0aMKNQPzcMIFgAAQGIUWAAAAIlRYAEAACRGgQUAAJAYBRYAAEBiFFgAAACJUWABAAAkRoEFAACQGAUWAABAYhRYAAAAiVFgAQAAJEaBBQAAkBgFFgAAQGLDmh1AI82ePbv0bW6//faF+h100EGF+p199tmF+gFAuxgzZkzhvo899ljCSIA3MIIFAACQGAUWAABAYv0WWLYvsr3C9sKqZefaftj2A7Zn2x7V2DABALUibwPNV8sI1sWSpvRYNkfSjhHxD5J+J+kLieMCABR3scjbQFP1W2BFxB2SVvZYdnNErMme3iNpfANiAwAUQN4Gmi/FHKxjJN2U4HUAAOUgbwMNVleBZfsMSWskXd7HOtNsd9nu6u7urmdzAIA69Ze3ydlAGoULLNtHSdpf0scjIvLWi4gZEdEZEZ0dHR1FNwcAqFMteZucDaRR6EKjtqdI+ryk90fEK2lDAgCkRt4GylXLZRqukHS3pO1sL7N9rKTzJY2UNMf2Atvfb3CcAIAakbeB5ut3BCsiDutl8cwGxAIASIC8DTQfV3IHAABIjAILAAAgsUKT3AeK119/vdkhAACAQYgRLAAAgMQosAAAABKjwAIAAEiMAgsAACAxCiwAAIDEKLAAAAASo8ACAABIjAILAAAgMQosAACAxCiwAAAAEqPAAgAASIwCCwAAIDEKLAAAgMQcEeVtzO6WtDSneayk50oLpm+tFIvUWvEQS76i8WwZER2pgwHqNYByttRa8RBL71opFqnBObvUAqsvtrsiorPZcUitFYvUWvEQS75WiwdopFb7e2+leIild60Ui9T4eDhFCAAAkBgFFgAAQGKtVGDNaHYAVVopFqm14iGWfK0WD9BIrfb33krxEEvvWikWqcHxtMwcLAAAgHbRSiNYAAAAbaH0Asv2FNuLbT9qe3ov7W+zfWXWPtf2xAbFsYXt22wvsv2Q7ZN6WWey7VW2F2S3LzUilmxbj9t+MNtOVy/ttv3tbL88YHuXBsayXdXPvMD2i7ZP7rFOw/aN7Ytsr7C9sGrZGNtzbD+S3Y/O6XtUts4jto9qUCzn2n44+z3Mtj0qp2+fv1NgICBn9xlTS+TtZufs7PXJ2z1FRGk3SUMlPSZpa0nDJd0vaYce6/yrpO9njw+VdGWDYhknaZfs8UhJv+sllsmSri9p3zwuaWwf7ftJukmSJe0qaW6Jv7NnVLnuRyn7RtKeknaRtLBq2dckTc8eT5f01V76jZG0JLsfnT0e3YBY9pE0LHv81d5iqeV3yo1bq9/I2f3G1HJ5uxk5O3t98naPW9kjWJMkPRoRSyLiVUk/ljS1xzpTJV2SPZ4laS/bTh1IRCyPiPnZ49WSFknaPPV2Epoq6dKouEfSKNvjStjuXpIei4i8iw0mFxF3SFrZY3H138Ulkg7qpeuHJc2JiJUR8bykOZKmpI4lIm6OiDXZ03skja9nG0ALI2fXpxl5u/ScLZG3e1N2gbW5pCerni/TW98gf10n2xmrJL2jkUFlQ9o7S5rbS/Nutu+3fZPtv2tgGCHpZtvzbE/rpb2WfdcIh0q6IqetrH0jSZtGxHKpkmglbdLLOs3YR8eo8h9qb/r7nQKtjpzdt1bM262Ss6VBnreH1dO5gN7+q+n5McZa1knG9ghJV0s6OSJe7NE8X5Vh1pds7yfpZ5K2bVAoe0TE07Y3kTTH9sNZFf7XUHvp09CPgNoeLulASV/opbnMfVOrsv92zpC0RtLlOav09zsFWh05u28tlbcHYM6W2jhvlz2CtUzSFlXPx0t6Om8d28Mkbay3DjsmYXs9Vd6ol0fET3u2R8SLEfFS9vhGSevZHtuIWCLi6ex+haTZqgzNV6tl36W2r6T5EfFsz4Yy903m2bVD69n9il7WKW0fZRMx95f08chO3PdUw+8UaHXk7D60YN5upZwtDfK8XXaBda+kbW1vlVXah0q6tsc610pa+ymCQyTdmrcj6pHNEZgpaVFEnJezzjvXziWwPUmV/fWHBsSyoe2Rax+rMhlvYY/VrpV0ZPaplF0lrVo79NpAhylnqLmsfVOl+u/iKEnX9LLOLyTtY3t09mmVfbJlSdmeIunzkg6MiFdy1qnldwq0OnJ2fjytmLdbKWdLgz1vp5gpvy43VT5V8TtVPplyRrbsy9kPLUnrS/qJpEcl/UbS1g2K432qDEM+IGlBdttP0mckfSZb53hJD6nyyZl7JO3eoFi2zrZxf7a9tfulOhZLuiDbbw9K6mzw72kDVd58G1ctK2XfqJIglkt6TZX/bo5VZU7HLZIeye7HZOt2Srqwqu8x2d/Oo5KOblAsj6oyZ2Dt383aT1BtJunGvn6n3LgNtBs5OzeelsrbzczZ2euTt3vcuJI7AABAYlzJHQAAIDEKLAAAgMQosAAAABKjwAIAAEiMAgsAACAxCiwAAIDEKLAAAAASo8ACAABI7P8DaSJSxXVGrJUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X_train[0]\n",
    "\n",
    "X_1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)(X)\n",
    "\n",
    "X_2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)(X)\n",
    "\n",
    "X_3 = -nn.MaxPool2d(kernel_size=2, stride=2, padding=0)(-X)\n",
    "\n",
    "fig=plt.figure(figsize=(12, 8))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.imshow(-X[0])\n",
    "plt.title(\"original\")\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.imshow(-X_1[0])\n",
    "plt.title(\"mean pooling\")\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.imshow(-X_2[0])\n",
    "plt.title(\"max pooling\")\n",
    "fig.add_subplot(2,2,4)\n",
    "plt.imshow(-X_3[0])\n",
    "plt.title(\"min pooling\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train[21]\n",
    "\n",
    "X_1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)(X)\n",
    "\n",
    "X_2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)(X)\n",
    "\n",
    "X_3 = -nn.MaxPool2d(kernel_size=2, stride=2, padding=0)(-X)\n",
    "\n",
    "fig=plt.figure(figsize=(12, 8))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.imshow(-X[0])\n",
    "plt.title(\"original\")\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.imshow(-X_1[0])\n",
    "plt.title(\"mean pooling\")\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.imshow(-X_2[0])\n",
    "plt.title(\"max pooling\")\n",
    "fig.add_subplot(2,2,4)\n",
    "plt.imshow(-X_3[0])\n",
    "plt.title(\"min pooling\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and training a CNN model on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Pytorch and other useful librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.gray()\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "\n",
    "def accuracy(Y_hat, Y):\n",
    "    preds = torch.argmax(Y_hat, dim=1)\n",
    "    return (preds == Y).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples :  60000\n",
      "Test examples :  10000\n",
      "Nb of features :  1\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "#load trainset into tensors\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)\n",
    "X_train = train_loader.dataset.data\n",
    "Y_train = train_loader.dataset.targets\n",
    "\n",
    "#load testset into tensors\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10000, shuffle=False)\n",
    "X_test = test_loader.dataset.data\n",
    "Y_test = test_loader.dataset.targets\n",
    "\n",
    "#scale data to [0:1] and convert to float32\n",
    "X_train = (X_train.to(dtype=torch.float32) / X_train.max().to(dtype=torch.float32))\n",
    "X_test = (X_test.to(dtype=torch.float32) / X_test.max().to(dtype=torch.float32))\n",
    "\n",
    "#Flatten train and test data\n",
    "X_train = X_train.reshape(X_train.shape[0],1,28,28)\n",
    "X_test = X_test.reshape(X_test.shape[0],1,28,28)\n",
    "\n",
    "print(\"Train examples : \",X_train.shape[0])\n",
    "print(\"Test examples : \",X_test.shape[0])\n",
    "print(\"Nb of features : \",X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=5, stride=1, padding=2)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.conv2 = nn.Conv2d(24, 48, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "        self.conv3 = nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.linear4 = nn.Linear(64*3*3,256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.linear5 = nn.Linear(256,10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        #print(\"--------FORWARD---------\")\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        #print(\"conv1 :\" , x.shape)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "        #print(\"max1 :\" , x.shape)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        #print(\"conv2 :\" , x.shape)\n",
    "        x = self.max2(x)\n",
    "        x = self.bn2(x)\n",
    "        #print(\"max2 :\" , x.shape)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        #print(\"conv3 :\" , x.shape)\n",
    "        x = self.max3(x)\n",
    "        x = self.bn3(x)\n",
    "        #print(\"max3 :\" , x.shape)\n",
    "        x = self.linear4(torch.relu(x.reshape(x.shape[0],-1)))\n",
    "        #print(\"linear4 :\" , x.shape)\n",
    "        x = self.bn4(x)\n",
    "        x = self.linear5(torch.softmax(x,1))\n",
    "        #print(\"linear5 :\" , x.shape)\n",
    "        return x\n",
    "                            \n",
    "                            \n",
    "    def fit(self,optimizer,epochs,batch_size,lr,decay):\n",
    "        n = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            #opt.param_groups[0]['lr'] = lr / (1+decay)\n",
    "                           \n",
    "            model.train()\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                \n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            print(epoch+1,\"\\t\",loss.item())\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                print(\"Test set \\t\", round(accuracy( model.forward(X_test) , Y_test).item(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 0.08516699075698853\n",
      "Test set \t 0.975\n",
      "2 \t 0.04562624916434288\n",
      "Test set \t 0.984\n",
      "3 \t 0.032392021268606186\n",
      "Test set \t 0.988\n",
      "4 \t 0.028965575620532036\n",
      "Test set \t 0.987\n",
      "5 \t 0.02674502693116665\n",
      "Test set \t 0.988\n",
      "6 \t 0.02047395147383213\n",
      "Test set \t 0.99\n",
      "7 \t 0.023352866992354393\n",
      "Test set \t 0.989\n",
      "8 \t 0.025886444374918938\n",
      "Test set \t 0.99\n",
      "9 \t 0.027795525267720222\n",
      "Test set \t 0.99\n",
      "10 \t 0.022772518917918205\n",
      "Test set \t 0.987\n",
      "11 \t 0.0373346172273159\n",
      "Test set \t 0.985\n",
      "12 \t 0.016209373250603676\n",
      "Test set \t 0.992\n",
      "13 \t 0.021052422001957893\n",
      "Test set \t 0.993\n",
      "14 \t 0.022053474560379982\n",
      "Test set \t 0.993\n",
      "15 \t 0.018207136541604996\n",
      "Test set \t 0.993\n",
      "16 \t 0.017679264768958092\n",
      "Test set \t 0.989\n",
      "17 \t 0.02370826154947281\n",
      "Test set \t 0.989\n",
      "18 \t 0.02704772911965847\n",
      "Test set \t 0.991\n",
      "19 \t 0.040121354162693024\n",
      "Test set \t 0.988\n",
      "20 \t 0.015256193466484547\n",
      "Test set \t 0.992\n"
     ]
    }
   ],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=1)\n",
    "opt_2 = optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 20\n",
    "batch_size = 600\n",
    "learning_rate = 1\n",
    "decay = 0.1\n",
    "\n",
    "model.fit(opt_2,epochs,batch_size,learning_rate,decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load, Preprocess and predict test set from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from CSV\n",
    "test = pd.read_csv('../data/MNIST/test.csv')\n",
    "test_tensor = torch.tensor(test.values)\n",
    "\n",
    "#Preprocess\n",
    "test_tensor = (test_tensor.to(dtype=torch.float32) / test_tensor.max().to(dtype=torch.float32))\n",
    "test_tensor = test_tensor.reshape(test_tensor.shape[0],1,28,28)\n",
    "\n",
    "#Predict\n",
    "test_tensor = model.forward(test_tensor)\n",
    "test_tensor = test_tensor.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save predictions to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to a numpy array\n",
    "arr = test_tensor.numpy()\n",
    "\n",
    "# write CSV\n",
    "np.savetxt('../data/MNIST/predictions.csv', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
