{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>A comprehensive example of CNN with Pytorch</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers.*\n",
    "\n",
    "__Deep Learning__, I. Goodfellow & al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim in this section is to use multiple methods introduced by CNN in order to outperform simple fully connected neural networks. We will first describe each method and explain the motivation behind. Then, we will train a model using all these methods and compare it to simple neural networks. \n",
    "\n",
    "Note : we will mostly use __Deep Learning__, I. Goodfellow & al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"table\"></a>\n",
    "- **I- [The convolution operator as a network simplifier](#convolution)**\n",
    "\t- 1- [Principle of convolution](#principle_conv)\n",
    "\t- 2- [Motivation behind convolution](#motivation_conv)\n",
    "- **II- [Pooling to improve statistical robustness](#pooling)**\n",
    "\t- 1- [What is pooling ?](#what_pool)\n",
    "\t- 2- [Different ways of pooling](#diff_pool)\n",
    "    - 3- [Pooling is useful for object detection](#detect_pool)\n",
    "- **III- [Batch normalization to reduce internal covariate shift](#batch)**\n",
    "\t- 1- [The problem of the internal covariate shift](#covariate)\n",
    "    - 2- [The method of Batch Normalization](#method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"convolution\"></a>\n",
    "# I- The convolution operator as a network simplifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III- Creating and training a CNN model on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Pytorch and other useful librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.gray()\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "\n",
    "def accuracy(Y_hat, Y):\n",
    "    preds = torch.argmax(Y_hat, dim=1)\n",
    "    return (preds == Y).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples :  60000\n",
      "Test examples :  10000\n",
      "Nb of features :  1\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "#load trainset into tensors\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)\n",
    "X_train = train_loader.dataset.data\n",
    "Y_train = train_loader.dataset.targets\n",
    "\n",
    "#load testset into tensors\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10000, shuffle=False)\n",
    "X_test = test_loader.dataset.data\n",
    "Y_test = test_loader.dataset.targets\n",
    "\n",
    "#scale data to [0:1] and convert to float32\n",
    "X_train = (X_train.to(dtype=torch.float32) / X_train.max().to(dtype=torch.float32))\n",
    "X_test = (X_test.to(dtype=torch.float32) / X_test.max().to(dtype=torch.float32))\n",
    "\n",
    "#Flatten train and test data\n",
    "X_train = X_train.reshape(X_train.shape[0],1,28,28)\n",
    "X_test = X_test.reshape(X_test.shape[0],1,28,28)\n",
    "\n",
    "print(\"Train examples : \",X_train.shape[0])\n",
    "print(\"Test examples : \",X_test.shape[0])\n",
    "print(\"Nb of features : \",X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=5, stride=1, padding=2)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.conv2 = nn.Conv2d(24, 48, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "        self.conv3 = nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.linear4 = nn.Linear(64*3*3,256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.linear5 = nn.Linear(256,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"--------FORWARD---------\")\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        #print(\"conv1 :\" , x.shape)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "        #print(\"max1 :\" , x.shape)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        #print(\"conv2 :\" , x.shape)\n",
    "        x = self.max2(x)\n",
    "        x = self.bn2(x)\n",
    "        #print(\"max2 :\" , x.shape)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        #print(\"conv3 :\" , x.shape)\n",
    "        x = self.max3(x)\n",
    "        x = self.bn3(x)\n",
    "        #print(\"max3 :\" , x.shape)\n",
    "        x = self.linear4(torch.relu(x.reshape(x.shape[0],-1)))\n",
    "        #print(\"linear4 :\" , x.shape)\n",
    "        x = self.bn4(x)\n",
    "        x = self.linear5(torch.softmax(x,1))\n",
    "        #print(\"linear5 :\" , x.shape)\n",
    "        return x\n",
    "    \n",
    "    def fit(self,optimizer,epochs,batch_size,lr,decay):\n",
    "        n = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            #opt.param_groups[0]['lr'] = lr / (1+decay)\n",
    "                           \n",
    "            model.train()\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                \n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            print(epoch+1,\"\\t\",loss.item())\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                print(\"Test set \\t\", round(accuracy( model.forward(X_test) , Y_test).item(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-e94e916a5093>, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-e94e916a5093>\"\u001b[0;36m, line \u001b[0;32m69\u001b[0m\n\u001b[0;31m    for param\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=5, stride=1, padding=2)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.conv2 = nn.Conv2d(24, 48, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "        self.conv3 = nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.linear4 = nn.Linear(64*3*3,256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.linear5 = nn.Linear(256,10)\n",
    "        \n",
    "        mu = [None] * 5\n",
    "        \n",
    "        self.copy_snapshot()\n",
    " \n",
    "    def forward(self, x):\n",
    "        #print(\"--------FORWARD---------\")\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        #print(\"conv1 :\" , x.shape)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "        #print(\"max1 :\" , x.shape)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        #print(\"conv2 :\" , x.shape)\n",
    "        x = self.max2(x)\n",
    "        x = self.bn2(x)\n",
    "        #print(\"max2 :\" , x.shape)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        #print(\"conv3 :\" , x.shape)\n",
    "        x = self.max3(x)\n",
    "        x = self.bn3(x)\n",
    "        #print(\"max3 :\" , x.shape)\n",
    "        x = self.linear4(torch.relu(x.reshape(x.shape[0],-1)))\n",
    "        #print(\"linear4 :\" , x.shape)\n",
    "        x = self.bn4(x)\n",
    "        x = self.linear5(torch.softmax(x,1))\n",
    "        #print(\"linear5 :\" , x.shape)\n",
    "        return x\n",
    "    \n",
    "    def forward_snapshot(self, x):\n",
    "        #print(\"--------FORWARD---------\")\n",
    "        x = torch.relu(self.conv1_snapshot(x))\n",
    "        #print(\"conv1 :\" , x.shape)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "        #print(\"max1 :\" , x.shape)\n",
    "        x = torch.relu(self.conv2_snapshot(x))\n",
    "        #print(\"conv2 :\" , x.shape)\n",
    "        x = self.max2(x)\n",
    "        x = self.bn2(x)\n",
    "        #print(\"max2 :\" , x.shape)\n",
    "        x = torch.relu(self.conv3_snapshot(x))\n",
    "        #print(\"conv3 :\" , x.shape)\n",
    "        x = self.max3(x)\n",
    "        x = self.bn3(x)\n",
    "        #print(\"max3 :\" , x.shape)\n",
    "        x = self.linear4_snapshot(torch.relu(x.reshape(x.shape[0],-1)))\n",
    "        #print(\"linear4 :\" , x.shape)\n",
    "        x = self.bn4(x)\n",
    "        x = self.linear5_snapshot(torch.softmax(x,1))\n",
    "        #print(\"linear5 :\" , x.shape)\n",
    "        return x\n",
    "    \n",
    "    def copy_snapshot(self):\n",
    "        self.conv1_snapshot = copy.deepcopy(self.conv1)\n",
    "        self.conv2_snapshot = copy.deepcopy(self.conv2)\n",
    "        self.conv3_snapshot = copy.deepcopy(self.conv3)\n",
    "        self.linear4_snapshot = copy.deepcopy(self.linear4)\n",
    "        self.linear5_snapshot = copy.deepcopy(self.linear5)\n",
    "\n",
    "    def update_SGD(self, x):\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def update_SVRG(self,lr):\n",
    "        params = list(net.parameters())\n",
    "        k = len(params)/2\n",
    "    \n",
    "    def update_mu(self):\n",
    "        for i in range(len(mu)):\n",
    "            mu[i] += \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(k):\n",
    "            params[i] -= lr * (params[i].grad() - params[i+k].grad() + mu[i])                          \n",
    "                            \n",
    "    def fit(self,optimizer,epochs,batch_size,lr,decay):\n",
    "        n = X_train.shape[0]\n",
    "        model.train()\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                \n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "            \n",
    "            self.copy_snapshot()\n",
    "            \n",
    "            \n",
    "            for m in range(5):\n",
    "                \n",
    "                \n",
    "                           \n",
    "            \n",
    "                for i in range((n - 1) // batch_size + 1):\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "\n",
    "                    pred = self.forward_snapshot( X )\n",
    "                    loss_snapshot = loss_func( pred , Y )\n",
    "\n",
    "                    loss_snapshot.backward()\n",
    "\n",
    "                    X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "\n",
    "                    pred = self.forward( X )\n",
    "                    loss = loss_func( pred , Y )\n",
    "\n",
    "                    loss.backward()\n",
    "\n",
    "                    self.update_SVRG(lr)\n",
    "                \n",
    "            print(epoch+1,\"\\t\",loss.item())\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                print(\"Test set \\t\", round(accuracy( model.forward(X_test) , Y_test).item(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 0.08516699075698853\n",
      "Test set \t 0.975\n",
      "2 \t 0.04562624916434288\n",
      "Test set \t 0.984\n",
      "3 \t 0.032392021268606186\n",
      "Test set \t 0.988\n",
      "4 \t 0.028965575620532036\n",
      "Test set \t 0.987\n",
      "5 \t 0.02674502693116665\n",
      "Test set \t 0.988\n",
      "6 \t 0.02047395147383213\n",
      "Test set \t 0.99\n",
      "7 \t 0.023352866992354393\n",
      "Test set \t 0.989\n",
      "8 \t 0.025886444374918938\n",
      "Test set \t 0.99\n",
      "9 \t 0.027795525267720222\n",
      "Test set \t 0.99\n",
      "10 \t 0.022772518917918205\n",
      "Test set \t 0.987\n",
      "11 \t 0.0373346172273159\n",
      "Test set \t 0.985\n",
      "12 \t 0.016209373250603676\n",
      "Test set \t 0.992\n",
      "13 \t 0.021052422001957893\n",
      "Test set \t 0.993\n",
      "14 \t 0.022053474560379982\n",
      "Test set \t 0.993\n",
      "15 \t 0.018207136541604996\n",
      "Test set \t 0.993\n",
      "16 \t 0.017679264768958092\n",
      "Test set \t 0.989\n",
      "17 \t 0.02370826154947281\n",
      "Test set \t 0.989\n",
      "18 \t 0.02704772911965847\n",
      "Test set \t 0.991\n",
      "19 \t 0.040121354162693024\n",
      "Test set \t 0.988\n",
      "20 \t 0.015256193466484547\n",
      "Test set \t 0.992\n"
     ]
    }
   ],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=1)\n",
    "epochs = 20\n",
    "batch_size = 600\n",
    "learning_rate = 0.1\n",
    "decay = 0.1\n",
    "\n",
    "model.fit(opt,epochs,batch_size,learning_rate,decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load, Preprocess and predict test set from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from CSV\n",
    "test = pd.read_csv('../data/MNIST/test.csv')\n",
    "test_tensor = torch.tensor(test.values)\n",
    "\n",
    "#Preprocess\n",
    "test_tensor = (test_tensor.to(dtype=torch.float32) / test_tensor.max().to(dtype=torch.float32))\n",
    "test_tensor = test_tensor.reshape(test_tensor.shape[0],1,28,28)\n",
    "\n",
    "#Predict\n",
    "test_tensor = model.forward(test_tensor)\n",
    "test_tensor = test_tensor.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save predictions to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-fb62caacb33f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Convert to a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# write CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/MNIST/predictions.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "#Convert to a numpy array\n",
    "arr = test_tensor.numpy()\n",
    "\n",
    "# write CSV\n",
    "np.savetxt('../data/MNIST/predictions.csv', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-58b00330f784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa[0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-52-e48999b6c343>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-e48999b6c343>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    len(aa) = 5\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "aa = list()\n",
    "aa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-58b00330f784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "aa[0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
