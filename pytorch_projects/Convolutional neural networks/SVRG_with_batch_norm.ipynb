{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Implementing SVRG in a state-of-the-art CNN model</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to implement SVRG in more complex models - such as CNN with batch normalization - and compare its convergence rate with SGD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I- Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Pytorch and other useful librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.gray()\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define auxiliary functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "\n",
    "def accuracy(Y_hat, Y):\n",
    "    preds = torch.argmax(Y_hat, dim=1)\n",
    "    return (preds == Y).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples :  60000\n",
      "Test examples :  10000\n",
      "Nb of features :  28\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "#load trainset into tensors\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)\n",
    "X_train = train_loader.dataset.data\n",
    "Y_train = train_loader.dataset.targets\n",
    "\n",
    "#load testset into tensors\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10000, shuffle=False)\n",
    "X_test = test_loader.dataset.data\n",
    "Y_test = test_loader.dataset.targets\n",
    "\n",
    "#scale data to [0:1] and convert to float32\n",
    "X_train = (X_train.to(dtype=torch.float32) / X_train.max().to(dtype=torch.float32))\n",
    "X_test = (X_test.to(dtype=torch.float32) / X_test.max().to(dtype=torch.float32))\n",
    "\n",
    "print(\"Train examples : \",X_train.shape[0])\n",
    "print(\"Test examples : \",X_test.shape[0])\n",
    "print(\"Nb of features : \",X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II- Implementing SVRG on a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(784,100)\n",
    "        self.linear2 = nn.Linear(100,10)\n",
    "        self.linear1_snapshot = nn.Linear(784,100)\n",
    "        self.linear2_snapshot = nn.Linear(100,10)\n",
    "        \n",
    "        self.number_params = 4 \n",
    "        \n",
    "        self.mu = [None] * self.number_params\n",
    "        \n",
    "        self.copy_snapshot()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.softmax(self.linear2(x),1)\n",
    "        return x\n",
    "    \n",
    "    def forward_snapshot(self, x):\n",
    "        x = torch.sigmoid(self.linear1_snapshot(x))\n",
    "        x = torch.softmax(self.linear2_snapshot(x),1)\n",
    "        return x\n",
    "    \n",
    "    def copy_snapshot(self):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(self.number_params):\n",
    "            params[i+self.number_params].data.copy_(params[i])\n",
    "\n",
    "        i=0\n",
    "        for param in self.parameters():\n",
    "            if (i < self.number_params) :\n",
    "                self.mu[i] = torch.zeros(param.shape)\n",
    "                i+=1\n",
    "\n",
    "    def update_SGD(self, lr=1):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(self.number_params):\n",
    "            params[i].data.copy_(params[i].data - lr * params[i].grad.data)\n",
    "\n",
    "    def update_SVRG(self,lr):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(self.number_params):\n",
    "            params[i].data.copy_(params[i].data - lr * (params[i].grad.data - params[i+self.number_params].grad.data + self.mu[i].data))       \n",
    "\n",
    "    def update_mu(self,n,batch_size):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(len(self.mu)):\n",
    "            self.mu[i].data.copy_(self.mu[i].data + params[i+self.number_params].grad.data / (n/batch_size))\n",
    "                            \n",
    "    def fit_SVRG(self,optimizer,epochs,warm_epochs,n,batch_size,lr):\n",
    "        params = list(self.parameters())\n",
    "        loss_graph = []\n",
    "        \n",
    "        n = X_train.shape[0]\n",
    "        self.train()\n",
    "        \n",
    "        #Warm start\n",
    "        for epoch in range(warm_epochs):\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "                loss.backward()\n",
    "                self.update_SGD(0.25)\n",
    "\n",
    "            loss_graph.append(loss.item())\n",
    "            print(epoch,\"\\t\",loss.item())\n",
    "\n",
    "        self.copy_snapshot()\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            #update mu\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                pred = self.forward_snapshot( X )\n",
    "                loss_snapshot = loss_func( pred , Y )\n",
    "\n",
    "                loss_snapshot.backward()\n",
    "\n",
    "                self.update_mu(n,batch_size)\n",
    "            \n",
    "            \n",
    "            for m in range(5):\n",
    "                for i in range((n - 1) // batch_size + 1):\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    #Snapshot gradient computation\n",
    "                    X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    X = self.forward_snapshot( X )\n",
    "                    loss_snapshot = loss_func( X , Y )\n",
    "                    loss_snapshot.backward()\n",
    "                    #'real' gradient computation\n",
    "                    X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    X = self.forward( X )\n",
    "                    loss = loss_func( X , Y )\n",
    "                    loss.backward()\n",
    "                    self.update_SVRG(lr)\n",
    "                \n",
    "                loss_graph.append(loss.item())\n",
    "                print(epoch * 5 + m+warm_epochs,\"\\t\",loss.item())\n",
    "            \n",
    "            self.copy_snapshot()\n",
    "            with torch.no_grad():\n",
    "                self.eval()\n",
    "                print(\"Test set \\t\", round(accuracy( self.forward(X_test.reshape(-1,784)) , Y_test).item(),3))\n",
    "            \n",
    "        return loss_graph\n",
    "\n",
    "    def fit_SGD(self,optimizer,epochs,batch_size,lr):\n",
    "        loss_graph = []\n",
    "        n = X_train.shape[0]\n",
    "       \n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "                loss.backward()\n",
    "                self.update_SGD(lr)\n",
    "            \n",
    "            loss_graph.append(loss.item())\n",
    "            print(epoch,\"\\t\",loss.item())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.eval()\n",
    "                print(\"Test set \\t\", round(accuracy( self.forward(X_test.reshape(-1,784)) , Y_test).item(),3))\n",
    "            \n",
    "        return loss_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000,784)\n",
    "epochs = 9\n",
    "warm_epochs = 5\n",
    "batch_size = 60\n",
    "learning_rate = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 1.9899097681045532\n",
      "1 \t 1.6986184120178223\n",
      "2 \t 1.6377289295196533\n",
      "3 \t 1.6269985437393188\n",
      "4 \t 1.621338963508606\n",
      "5 \t 1.6149697303771973\n",
      "6 \t 1.5586248636245728\n",
      "7 \t 1.5240319967269897\n",
      "8 \t 1.5112348794937134\n",
      "9 \t 1.5015599727630615\n",
      "Test set \t 0.933\n",
      "10 \t 1.4899380207061768\n",
      "11 \t 1.4854739904403687\n",
      "12 \t 1.4826315641403198\n",
      "13 \t 1.48070228099823\n",
      "14 \t 1.479218602180481\n",
      "Test set \t 0.943\n",
      "15 \t 1.474609136581421\n",
      "16 \t 1.4734580516815186\n",
      "17 \t 1.47251558303833\n",
      "18 \t 1.4716854095458984\n",
      "19 \t 1.470935583114624\n",
      "Test set \t 0.95\n",
      "20 \t 1.470125675201416\n",
      "21 \t 1.469614028930664\n",
      "22 \t 1.469159483909607\n",
      "23 \t 1.4687548875808716\n",
      "24 \t 1.4683871269226074\n",
      "Test set \t 0.956\n",
      "25 \t 1.4680085182189941\n",
      "26 \t 1.4676709175109863\n",
      "27 \t 1.4673434495925903\n",
      "28 \t 1.467032551765442\n",
      "29 \t 1.4667414426803589\n",
      "Test set \t 0.96\n",
      "30 \t 1.466991662979126\n",
      "31 \t 1.4667099714279175\n",
      "32 \t 1.466439962387085\n",
      "33 \t 1.4661825895309448\n",
      "34 \t 1.4659515619277954\n",
      "Test set \t 0.963\n",
      "35 \t 1.4661186933517456\n",
      "36 \t 1.465930700302124\n",
      "37 \t 1.465793251991272\n",
      "38 \t 1.4656952619552612\n",
      "39 \t 1.4656236171722412\n",
      "Test set \t 0.965\n",
      "40 \t 1.4659377336502075\n",
      "41 \t 1.4658710956573486\n",
      "42 \t 1.4658169746398926\n",
      "43 \t 1.4657758474349976\n",
      "44 \t 1.4657516479492188\n",
      "Test set \t 0.966\n",
      "45 \t 1.4659277200698853\n",
      "46 \t 1.465928554534912\n",
      "47 \t 1.4659384489059448\n",
      "48 \t 1.465955376625061\n",
      "49 \t 1.4659770727157593\n",
      "Test set \t 0.967\n"
     ]
    }
   ],
   "source": [
    "simple_mod = SimpleNet()\n",
    "opt = optim.SGD(simple_mod.parameters(), lr=10)\n",
    "loss_SVRG = simple_mod.fit_SVRG(opt,epochs,warm_epochs,X_train.shape[0],batch_size,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 1.9338434934616089\n",
      "Test set \t 0.585\n",
      "1 \t 1.7983834743499756\n",
      "Test set \t 0.666\n",
      "2 \t 1.7546272277832031\n",
      "Test set \t 0.734\n",
      "3 \t 1.6593934297561646\n",
      "Test set \t 0.823\n",
      "4 \t 1.6289886236190796\n",
      "Test set \t 0.842\n",
      "5 \t 1.5615859031677246\n",
      "Test set \t 0.905\n",
      "6 \t 1.5392341613769531\n",
      "Test set \t 0.912\n",
      "7 \t 1.525741457939148\n",
      "Test set \t 0.919\n",
      "8 \t 1.5156439542770386\n",
      "Test set \t 0.923\n",
      "9 \t 1.5076459646224976\n",
      "Test set \t 0.926\n",
      "10 \t 1.5009576082229614\n",
      "Test set \t 0.928\n",
      "11 \t 1.4952515363693237\n",
      "Test set \t 0.931\n",
      "12 \t 1.490461826324463\n",
      "Test set \t 0.933\n",
      "13 \t 1.486564040184021\n",
      "Test set \t 0.935\n",
      "14 \t 1.4834721088409424\n",
      "Test set \t 0.937\n",
      "15 \t 1.4810388088226318\n",
      "Test set \t 0.938\n",
      "16 \t 1.4791264533996582\n",
      "Test set \t 0.94\n",
      "17 \t 1.4776209592819214\n",
      "Test set \t 0.942\n",
      "18 \t 1.4764236211776733\n",
      "Test set \t 0.943\n",
      "19 \t 1.475460410118103\n",
      "Test set \t 0.944\n",
      "20 \t 1.4746752977371216\n",
      "Test set \t 0.944\n",
      "21 \t 1.4740196466445923\n",
      "Test set \t 0.946\n",
      "22 \t 1.4734504222869873\n",
      "Test set \t 0.947\n",
      "23 \t 1.4729386568069458\n",
      "Test set \t 0.948\n",
      "24 \t 1.472467064857483\n",
      "Test set \t 0.949\n",
      "25 \t 1.4720234870910645\n",
      "Test set \t 0.95\n",
      "26 \t 1.4715973138809204\n",
      "Test set \t 0.95\n",
      "27 \t 1.4711827039718628\n",
      "Test set \t 0.951\n",
      "28 \t 1.4707781076431274\n",
      "Test set \t 0.951\n",
      "29 \t 1.4703818559646606\n",
      "Test set \t 0.952\n",
      "30 \t 1.4699925184249878\n",
      "Test set \t 0.952\n",
      "31 \t 1.4696086645126343\n",
      "Test set \t 0.953\n",
      "32 \t 1.469228982925415\n",
      "Test set \t 0.954\n",
      "33 \t 1.4688541889190674\n",
      "Test set \t 0.955\n",
      "34 \t 1.4684876203536987\n",
      "Test set \t 0.955\n",
      "35 \t 1.4681330919265747\n",
      "Test set \t 0.955\n",
      "36 \t 1.4677926301956177\n",
      "Test set \t 0.956\n",
      "37 \t 1.4674710035324097\n",
      "Test set \t 0.957\n",
      "38 \t 1.4671696424484253\n",
      "Test set \t 0.957\n",
      "39 \t 1.4668911695480347\n",
      "Test set \t 0.958\n",
      "40 \t 1.4666366577148438\n",
      "Test set \t 0.959\n",
      "41 \t 1.4664057493209839\n",
      "Test set \t 0.959\n",
      "42 \t 1.4661964178085327\n",
      "Test set \t 0.96\n",
      "43 \t 1.4660056829452515\n",
      "Test set \t 0.96\n",
      "44 \t 1.4658300876617432\n",
      "Test set \t 0.96\n",
      "45 \t 1.4656685590744019\n",
      "Test set \t 0.96\n",
      "46 \t 1.4655194282531738\n",
      "Test set \t 0.961\n",
      "47 \t 1.4653816223144531\n",
      "Test set \t 0.961\n",
      "48 \t 1.4652533531188965\n",
      "Test set \t 0.961\n",
      "49 \t 1.4651333093643188\n",
      "Test set \t 0.961\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "simple_mod = SimpleNet()\n",
    "opt = optim.SGD(simple_mod.parameters(), lr=10)\n",
    "loss_SGD = simple_mod.fit_SGD(opt,epochs,batch_size,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbb65592908>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 8)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss (cross entropy)\")\n",
    "plt.plot(loss_SVRG,label = \"SVRG\")\n",
    "plt.plot(loss_SGD,label = \"SGD\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=5, stride=1, padding=2)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.conv2 = nn.Conv2d(24, 48, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "        self.conv3 = nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.linear4 = nn.Linear(64*3*3,256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.linear5 = nn.Linear(256,10)\n",
    "        \n",
    "        self.conv1_snapshot = nn.Conv2d(1, 24, kernel_size=5, stride=1, padding=2)\n",
    "        self.max1_snapshot = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn1_snapshot = nn.BatchNorm2d(24)\n",
    "        self.conv2_snapshot = nn.Conv2d(24, 48, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2_snapshot = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn2_snapshot = nn.BatchNorm2d(48)\n",
    "        self.conv3_snapshot = nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.max3_snapshot = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bn3_snapshot = nn.BatchNorm2d(64)\n",
    "        self.linear4_snapshot = nn.Linear(64*3*3,256)\n",
    "        self.bn4_snapshot = nn.BatchNorm1d(256)\n",
    "        self.linear5_snapshot = nn.Linear(256,10)\n",
    "        \n",
    "        self.number_params = 18\n",
    "        \n",
    "        self.mu = [None] * self.number_params\n",
    "        \n",
    "        self.copy_snapshot()\n",
    " \n",
    "    def forward(self, x):\n",
    "        #print(\"--------FORWARD---------\")\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        #print(\"conv1 :\" , x.shape)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "        #print(\"max1 :\" , x.shape)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        #print(\"conv2 :\" , x.shape)\n",
    "        x = self.max2(x)\n",
    "        x = self.bn2(x)\n",
    "        #print(\"max2 :\" , x.shape)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        #print(\"conv3 :\" , x.shape)\n",
    "        x = self.max3(x)\n",
    "        x = self.bn3(x)\n",
    "        #print(\"max3 :\" , x.shape)\n",
    "        x = torch.relu(self.linear4(x.reshape(x.shape[0],-1)))\n",
    "        #print(\"linear4 :\" , x.shape)\n",
    "        x = self.bn4(x)\n",
    "        x = torch.softmax(self.linear5(x),1)\n",
    "        #print(\"linear5 :\" , x.shape)\n",
    "        return x\n",
    "    \n",
    "    def forward_snapshot(self, x):\n",
    "        #print(\"--------FORWARD---------\")\n",
    "        x = torch.relu(self.conv1_snapshot(x))\n",
    "        #print(\"conv1 :\" , x.shape)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1_snapshot(x)\n",
    "        #print(\"max1 :\" , x.shape)\n",
    "        x = torch.relu(self.conv2_snapshot(x))\n",
    "        #print(\"conv2 :\" , x.shape)\n",
    "        x = self.max2(x)\n",
    "        x = self.bn2_snapshot(x)\n",
    "        #print(\"max2 :\" , x.shape)\n",
    "        x = torch.relu(self.conv3_snapshot(x))\n",
    "        #print(\"conv3 :\" , x.shape)\n",
    "        x = self.max3(x)\n",
    "        x = self.bn3_snapshot(x)\n",
    "        #print(\"max3 :\" , x.shape)\n",
    "        x = torch.relu(self.linear4_snapshot(x.reshape(x.shape[0],-1)))\n",
    "        #print(\"linear4 :\" , x.shape)\n",
    "        x = self.bn4_snapshot(x)\n",
    "        x = torch.softmax(self.linear5_snapshot(x),1)\n",
    "        #print(\"linear5 :\" , x.shape)\n",
    "        return x\n",
    "    \n",
    "    def copy_snapshot(self):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(self.number_params):\n",
    "            params[i+self.number_params].data.copy_(params[i])\n",
    "        i=0\n",
    "        for param in self.parameters():\n",
    "            if (i < self.number_params) :\n",
    "                self.mu[i] = torch.zeros(param.shape)\n",
    "                i+=1\n",
    "\n",
    "    def update_SGD(self, lr=1):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(self.number_params):\n",
    "            params[i].data.copy_(params[i].data - lr * params[i].grad.data)\n",
    "\n",
    "    def update_SVRG(self,lr):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(self.number_params):\n",
    "            params[i].data.copy_(params[i].data - lr * (params[i].grad.data - params[i+self.number_params].grad.data + self.mu[i].data))       \n",
    "\n",
    "    def update_mu(self,n,batch_size):\n",
    "        params = list(self.parameters())\n",
    "        for i in range(len(self.mu)):\n",
    "            self.mu[i].data.copy_(self.mu[i].data + params[i+self.number_params].grad.data / (n/batch_size))\n",
    "                            \n",
    "    def fit_SVRG(self,optimizer,epochs,warm_epochs,n,batch_size,lr):\n",
    "        params = list(self.parameters())\n",
    "        \n",
    "        n = X_train.shape[0]\n",
    "        self.train()\n",
    "        \n",
    "        #Warm start\n",
    "        for epoch in range(warm_epochs):\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "                loss.backward()\n",
    "                self.update_SGD(0.1)\n",
    "                \n",
    "            print(epoch,\"\\t\",loss.item())\n",
    "\n",
    "        self.copy_snapshot()\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            #update mu\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                pred = self.forward_snapshot( X )\n",
    "                loss_snapshot = loss_func( pred , Y )\n",
    "\n",
    "                loss_snapshot.backward()\n",
    "\n",
    "                self.update_mu(n,batch_size)\n",
    "            \n",
    "            \n",
    "            for m in range(5):\n",
    "                for i in range((n - 1) // batch_size + 1):\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    #Snapshot gradient computation\n",
    "                    X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    X = self.forward_snapshot( X )\n",
    "                    loss_snapshot = loss_func( X , Y )\n",
    "                    loss_snapshot.backward()\n",
    "                    #'real' gradient computation\n",
    "                    X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                    X = self.forward( X )\n",
    "                    loss = loss_func( X , Y )\n",
    "                    loss.backward()\n",
    "                    self.update_SVRG(lr)\n",
    "                    \n",
    "                print(epoch * 5 + m +warm_epochs,\"\\t\",loss.item())\n",
    "            \n",
    "            self.copy_snapshot()\n",
    "            with torch.no_grad():\n",
    "                self.eval()\n",
    "                print(\"Test set \\t\", round(accuracy( self.forward( X_test ) , Y_test).item(),3))\n",
    "\n",
    "    def fit_SGD(self,optimizer,epochs,batch_size,lr):\n",
    "        n = X_train.shape[0]\n",
    "       \n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                optimizer.zero_grad()\n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "                loss.backward()\n",
    "                self.update_SGD(lr)\n",
    "                \n",
    "            print(epoch,\"\\t\",loss.item())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.eval()\n",
    "                print(\"Test set \\t\", round(accuracy( self.forward( X_test ) , Y_test).item(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 1.782957911491394\n",
      "1 \t 1.5898760557174683\n",
      "2 \t 1.5451345443725586\n",
      "3 \t 1.5209664106369019\n",
      "4 \t 1.5085258483886719\n",
      "Test set \t 0.954\n",
      "5 \t 1.4949973821640015\n",
      "6 \t 1.4894193410873413\n",
      "7 \t 1.485562801361084\n",
      "8 \t 1.4824090003967285\n",
      "9 \t 1.4801219701766968\n",
      "Test set \t 0.98\n",
      "10 \t 1.4785144329071045\n",
      "11 \t 1.4771745204925537\n",
      "12 \t 1.4759944677352905\n",
      "13 \t 1.474901556968689\n",
      "14 \t 1.473824143409729\n",
      "Test set \t 0.981\n",
      "15 \t 1.472571849822998\n",
      "16 \t 1.4717108011245728\n",
      "17 \t 1.4711642265319824\n",
      "18 \t 1.470638632774353\n",
      "19 \t 1.470239520072937\n",
      "Test set \t 0.981\n",
      "20 \t 1.4698774814605713\n",
      "21 \t 1.46943998336792\n",
      "22 \t 1.4688915014266968\n",
      "23 \t 1.468032717704773\n",
      "24 \t 1.467490792274475\n",
      "Test set \t 0.982\n"
     ]
    }
   ],
   "source": [
    "#Flatten train and test data\n",
    "X_train = X_train.reshape(X_train.shape[0],1,28,28)\n",
    "X_test = X_test.reshape(X_test.shape[0],1,28,28)\n",
    "\n",
    "model = NeuralNet()\n",
    "opt = optim.SGD(model.parameters(), lr=10)\n",
    "epochs = 5\n",
    "warm_epochs = 0\n",
    "batch_size = 600\n",
    "learning_rate = 0.25\n",
    "\n",
    "model.fit_SVRG(opt,epochs,warm_epochs,X_train.shape[0],batch_size,learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load, Preprocess and predict test set from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from CSV\n",
    "test = pd.read_csv('../data/MNIST/test.csv')\n",
    "test_tensor = torch.tensor(test.values)\n",
    "\n",
    "#Preprocess\n",
    "test_tensor = (test_tensor.to(dtype=torch.float32) / test_tensor.max().to(dtype=torch.float32))\n",
    "test_tensor = test_tensor.reshape(test_tensor.shape[0],1,28,28)\n",
    "\n",
    "#Predict\n",
    "test_tensor = model.forward(test_tensor)\n",
    "test_tensor = test_tensor.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save predictions to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fb62caacb33f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Convert to a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# write CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/MNIST/predictions.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "#Convert to a numpy array\n",
    "arr = test_tensor.numpy()\n",
    "\n",
    "# write CSV\n",
    "np.savetxt('../data/MNIST/predictions.csv', arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
