{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Neural network with Pytorch</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use `torch.module` and `torch.optimizer` to create our neural network. We train it on MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "\n",
    "def accuracy(Y_hat, Y):\n",
    "    preds = torch.argmax(Y_hat, dim=1)\n",
    "    return (preds == Y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "#load trainset into tensors\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)\n",
    "X_train = train_loader.dataset.data\n",
    "Y_train = train_loader.dataset.targets\n",
    "\n",
    "#load testset into tensors\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10000, shuffle=False)\n",
    "X_test = test_loader.dataset.data\n",
    "Y_test = test_loader.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples :  60000\n",
      "Test examples :  10000\n",
      "Nb of features :  784\n"
     ]
    }
   ],
   "source": [
    "#scale data to [0:1] and convert to float32\n",
    "X_train = (X_train.to(dtype=torch.float32) / X_train.max().to(dtype=torch.float32))\n",
    "X_test = (X_test.to(dtype=torch.float32) / X_test.max().to(dtype=torch.float32))\n",
    "\n",
    "#Flatten train and test data\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "print(\"Train examples : \",X_train.shape[0])\n",
    "print(\"Test examples : \",X_test.shape[0])\n",
    "print(\"Nb of features : \",X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128,64)  \n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc5 = nn.Linear(64,32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.fc6 = nn.Linear(32,16)   \n",
    "        self.bn6 = nn.BatchNorm1d(16)\n",
    "        self.fc7 = nn.Linear(16,10)        \n",
    " \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.bn4(x)\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.bn5(x)\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.bn6(x)\n",
    "        x = torch.sigmoid(self.fc7(x))\n",
    "        return x\n",
    "                            \n",
    "                            \n",
    "    def fit(self,optimizer,epochs,batch_size):\n",
    "        n = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            for i in range((n - 1) // batch_size + 1):\n",
    "                \n",
    "                X = X_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                Y = Y_train[ i * batch_size : (i+1) * batch_size ]\n",
    "                \n",
    "                pred = self.forward( X )\n",
    "                loss = loss_func( pred , Y )\n",
    "\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "            print(epoch+1,\"\\t\",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [784,512,256,128,64,32,16,10]\n",
    "\n",
    "model = NeuralNet()\n",
    "opt = optim.SGD(model.parameters(), lr=1)\n",
    "opt_2 = optim.Adam(model.parameters(), lr=0.1, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 1.5673637390136719\n",
      "2 \t 1.5133841037750244\n",
      "3 \t 1.4983447790145874\n",
      "4 \t 1.4907454252243042\n",
      "5 \t 1.4882878065109253\n",
      "6 \t 1.4871314764022827\n",
      "7 \t 1.4854809045791626\n",
      "8 \t 1.484190583229065\n",
      "9 \t 1.485247015953064\n",
      "10 \t 1.4839437007904053\n",
      "11 \t 1.4839590787887573\n",
      "12 \t 1.482917308807373\n",
      "13 \t 1.4832372665405273\n",
      "14 \t 1.4835891723632812\n",
      "15 \t 1.482880711555481\n",
      "16 \t 1.4863377809524536\n",
      "17 \t 1.482969045639038\n",
      "18 \t 1.4832115173339844\n",
      "19 \t 1.4830360412597656\n",
      "20 \t 1.4823493957519531\n"
     ]
    }
   ],
   "source": [
    "model.fit(opt,20,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set :  0.896\n"
     ]
    }
   ],
   "source": [
    "preds = model.forward(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy on test set : \", round(accuracy( preds , Y_test).item(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
