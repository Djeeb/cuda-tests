{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Neural network from scratch</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we don't use any `torch.module` nor `torch.optimizer` to create our neural network. We train it on MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(x):\n",
    "    x = torch.relu(x @ weights_1 + bias_1) #First activation function\n",
    "    x = torch.sigmoid(x @ weights_2 + bias_2) #Second activation function\n",
    "    return x\n",
    "\n",
    "def accuracy(Y_hat, Y):\n",
    "    preds = torch.argmax(Y_hat, dim=1)\n",
    "    return (preds == Y).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "#load trainset into tensors\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)\n",
    "X_train = train_loader.dataset.data\n",
    "Y_train = train_loader.dataset.targets\n",
    "\n",
    "#load testset into tensors\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10000, shuffle=False)\n",
    "X_test = test_loader.dataset.data\n",
    "Y_test = test_loader.dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples :  60000\n",
      "Test examples :  10000\n",
      "Nb of features :  784\n"
     ]
    }
   ],
   "source": [
    "#scale data to [0:1] and convert to float32\n",
    "X_train = (X_train.to(dtype=torch.float32) / X_train.max().to(dtype=torch.float32))\n",
    "X_test = (X_test.to(dtype=torch.float32) / X_test.max().to(dtype=torch.float32))\n",
    "\n",
    "#Flatten train and test data\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "print(\"Train examples : \",X_train.shape[0])\n",
    "print(\"Test examples : \",X_test.shape[0])\n",
    "print(\"Nb of features : \",X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = (torch.rand((784, 64) , dtype = torch.float32 ) * 2 - 1 ) / math.sqrt(784)\n",
    "weights_1.requires_grad_()\n",
    "bias_1 = torch.zeros(64, requires_grad=True)\n",
    "\n",
    "weights_2 = (torch.rand((64, 10) , dtype = torch.float32 ) * 2 - 1 ) / math.sqrt(64) \n",
    "weights_2.requires_grad_()\n",
    "bias_2 = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t 1.5122243165969849\n",
      "20 \t 1.4995709657669067\n",
      "30 \t 1.4941699504852295\n",
      "40 \t 1.491289734840393\n",
      "50 \t 1.4891860485076904\n",
      "60 \t 1.487610936164856\n",
      "70 \t 1.4862712621688843\n",
      "80 \t 1.485148310661316\n",
      "90 \t 1.4843205213546753\n",
      "100 \t 1.4837138652801514\n"
     ]
    }
   ],
   "source": [
    "lr_init = 1 #learning rate initialization\n",
    "decay = 0.01  # learning rate\n",
    "epochs = 100  # how many epochs to train for\n",
    "n = X_train.shape[0] #number of training examples\n",
    "batch_size = 600\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lr = lr_init / (1 + decay * epoch)\n",
    "    for i in range(n // batch_size):\n",
    "        X = X_train[i*batch_size: (i+1) *batch_size]\n",
    "        Y = Y_train[i*batch_size: (i+1) *batch_size]\n",
    "        X = model(X)\n",
    "\n",
    "        loss = loss_func( X , Y )\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            weights_1 -= weights_1.grad * lr\n",
    "            weights_2 -= weights_2.grad * lr\n",
    "            bias_1 -= bias_1.grad * lr\n",
    "            bias_2 -= bias_2.grad * lr\n",
    "            \n",
    "            weights_1.grad.zero_()\n",
    "            weights_2.grad.zero_()\n",
    "            bias_1.grad.zero_()\n",
    "            bias_2.grad.zero_()    \n",
    "            \n",
    "    if((epoch+1)%10 == 0):\n",
    "        print(epoch + 1 , \"\\t\", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set :  0.966\n"
     ]
    }
   ],
   "source": [
    "preds = model(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy on test set : \", round(accuracy( preds , Y_test).item(),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
