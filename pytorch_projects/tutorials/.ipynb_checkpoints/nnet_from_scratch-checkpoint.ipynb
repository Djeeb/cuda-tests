{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(x):\n",
    "    return x @ weights + bias\n",
    "\n",
    "def accuracy(Y_hat, Y):\n",
    "    preds = torch.argmax(Y_hat, dim=1)\n",
    "    return (preds == Y).float().mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "#load train set into tensors\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)\n",
    "X_train = train_loader.dataset.data\n",
    "Y_train = train_loader.dataset.targets\n",
    "\n",
    "#load train set into tensors\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10000, shuffle=False)\n",
    "X_test = test_loader.dataset.data\n",
    "Y_test = test_loader.dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples :  60000\n",
      "Test examples :  10000\n",
      "Nb of features :  784\n"
     ]
    }
   ],
   "source": [
    "#scale data to [0:1] and convert to float32\n",
    "X_train = (X_train.to(dtype=torch.float32) / X_train.max().to(dtype=torch.float32))\n",
    "X_test = (X_test.to(dtype=torch.float32) / X_test.max().to(dtype=torch.float32))\n",
    "\n",
    "#Flatten train and test data\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "print(\"Train examples : \",X_train.shape[0])\n",
    "print(\"Test examples : \",X_test.shape[0])\n",
    "print(\"Nb of features : \",X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t 0.24010531604290009\n",
      "20 \t 0.22596538066864014\n",
      "30 \t 0.218764528632164\n",
      "40 \t 0.2140415608882904\n",
      "50 \t 0.21055547893047333\n",
      "60 \t 0.20781202614307404\n",
      "70 \t 0.20556947588920593\n",
      "80 \t 0.203690767288208\n",
      "90 \t 0.20208892226219177\n",
      "100 \t 0.20070534944534302\n"
     ]
    }
   ],
   "source": [
    "lr_init = 0.5 #learning rate initialization\n",
    "decay = 1  # learning rate\n",
    "epochs = 100  # how many epochs to train for\n",
    "n = X_train.shape[0] #number of training examples\n",
    "batch_size = 1000\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lr = lr_init / (1 + decay * epoch)\n",
    "    for i in range(n // batch_size):\n",
    "        X = X_train[i*batch_size: (i+1) *batch_size]\n",
    "        Y = Y_train[i*batch_size: (i+1) *batch_size]\n",
    "        X = model(X)\n",
    "\n",
    "        loss = loss_func( X , Y )\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "    \n",
    "    if((epoch+1)%10 == 0):\n",
    "        print(epoch + 1 , \"\\t\", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set :  0.926\n"
     ]
    }
   ],
   "source": [
    "preds = model(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy on test set : \", round(accuracy( preds , Y_test).item(),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
